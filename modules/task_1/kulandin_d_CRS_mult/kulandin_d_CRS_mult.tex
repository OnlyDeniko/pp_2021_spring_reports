\documentclass{report}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{luainputenc}
\usepackage[english, russian]{babel}
\usepackage[pdftex]{hyperref}
\usepackage[14pt]{extsizes}
\usepackage{listings}
\usepackage{color}
\usepackage{geometry}
\usepackage{indentfirst}
\usepackage{pgfplots}

\geometry{a4paper,top=2cm,bottom=3cm,left=2cm,right=1.5cm}
\setlength{\parskip}{0.5cm}

\lstset{
    language=C++,
	numbers=left,
	basicstyle=\footnotesize,
	keywordstyle=\color{blue}\ttfamily,
	stringstyle=\color{red}\ttfamily,
	commentstyle=\color{green}\ttfamily,
	morecomment=[l][\color{magenta}]{\#}, 
	tabsize=2,
	title=\lstname,       
}

\makeatletter
\renewcommand\@biblabel[1]{#1.\hfil}
\makeatother

\begin{document}

\begin{titlepage}

\begin{center}
Министерство науки и высшего образования Российской Федерации
\end{center}

\begin{center}
Федеральное государственное автономное образовательное учреждение высшего образования \\
Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского
\end{center}

\begin{center}
Институт информационных технологий, математики и механики
\end{center}

\vspace{4em}

\begin{center}
\textbf{\LargeОтчет по лабораторной работе} \\
\end{center}
\begin{center}
\textbf{\LargeУмножение разреженных матриц. Элементы комплексного типа. Формат хранения матрицы – строковый (CRS)} \\
\end{center}

\vspace{4em}

\newbox{\lbox}
\savebox{\lbox}{\hbox{text}}
\newlength{\maxl}
\setlength{\maxl}{\wd\lbox}
\hfill\parbox{7cm}{
\hspace*{5cm}\hspace*{-5cm}\textbf{Выполнил:} \\ студент группы 381806-2 \\ Куландин Д.С.\\
\\
\hspace*{5cm}\hspace*{-5cm}\textbf{Проверил:}\\ доцент кафедры МОСТ, \\ кандидат технических наук \\ Сысоев А. В.
}

\vspace{\fill}

\begin{center} Нижний Новгород \\ 2021 \end{center}

\end{titlepage}

\setcounter{page}{2}

% Содержание
\tableofcontents
\newpage

% Введение
\section*{Введение}
\addcontentsline{toc}{section}{Введение}
Матрицы, которые содержат в основном нулевые значения, называются разреженными, в отличие от матриц, где большинство значений отличны от нуля, которые называются плотными.

Большие разреженные матрицы распространены в общем и особенно в прикладном машинном обучении, например, в данных, которые содержат счетчики, кодировки данных, которые отображают категории в счетчики, и даже во всех подполях машинного обучения, таких как обработка естественного языка.

В вычислительном отношении дорого представлять и работать с разреженными матрицами, как если бы они были плотными, и можно добиться значительного улучшения производительности, используя представления и операции, которые специально обрабатывают разреженность матриц.

\newpage

% Постановка задачи
\section*{Постановка задачи}
\addcontentsline{toc}{section}{Постановка задачи}
В рамках лабораторной работы нужно реализовать алгоритм умножения разреженных матриц с элементами комплексного типа, используя строковый формат хранения.

\par Для этого нужно выполнить следующую последовательность действий:

\begin{enumerate}
\item Изучить способы хранения разреженных матриц
\item Разработать программную инфраструктуру для проведения экспериментов - генератора разреженных матриц с заданным процентом ненулевых элементов, метод для проверки корректности умножения матриц
\item Разработать последовательную версию алгоритма
\item Реализовать распараллеливание с использованием OpenMP, TBB и std::thread
\item Осуществить проверку корректности работы алгоритмов с помощью тестов, созданных с использованием Google C++ Testing Framework
\item Провести вычислительные эксперименты и сделать соответствующие выводы
\end{enumerate}
\newpage

% Метод решения
\section*{Метод решения}
\addcontentsline{toc}{section}{Метод решения}
Хранение разреженной матрицы осуществляется с помощью структуры, которая содержит следующие поля:
\begin{enumerate}
\item Размерность матрицы
\item Массив для хранения ненулевых элементов
\item Массив, хранящий номера столбцов для каждого элемента
\item Массив, содержащий диапазон индексов в остальных массивах, для определения какой строке принадлежит соответствующий элемент
\end{enumerate}
В качестве тестовых матриц будут использоваться случайно созданные матрицы с заданным процентом заполнения. Проверка корректности алгоритма умножения проводится с помощью метода, который переводит разреженную матрицу в плотную и выполняет стандартное умножение плотных матриц за $\mathcal{O}(n^3)$

\par Метод реализующий алгоритм умножения принимает на вход две разреженных матрицы A и B в строковом формате хранения и возвращает их произведение - разреженную матрицу С. Опишем его шаги:
\begin{enumerate}
\item Создаем три вспомогательных массива для хранения результирующей матрицы С
\item Транспонируем матрицу B алгоритмом Густавсона
\item В цикле идем по строками матрицы A, во внутреннем цикле идем по всем строками транспонированной матрицы B
\item Вычисляем скалярное произведение двух зафиксированных разреженных строк матриц A и транспонированной B. Если оно отлично от 0, тогда добавляем его и номер столбца в соответствующие массивы
\item После прохода по каждой строке из транспонированной B записываем в массив индексов текущее количество ненулевых элементов в результирующей матрицы.
\end{enumerate}
По окончании работы алгоритма, в вспомогательных массивах будет храниться результирующая разреженная матрица С.

\newpage

\section*{Скалярное умножение разреженных строк}
\addcontentsline{toc}{section}{Скалярное умножение разреженных строк}

Наивная реализация заключается в проходе по массиву столбцов для матрицы А и проходу по массиву столбцов транспонированной матрицы В. Если номера столбцов совпадут, то добавляем в результат произведение двух элементов. Данное решение будет работать за $\mathcal{O}(n^2)$.

\par Можно заметить, что для фиксированной строки номера столбцов будут отсортированны по возрастанию. Это значит, что подсчет скалярного произведения возможно реализовать с помощью двух указателей, как это сделано в функции слияния в сортировке слиянием.
То есть у нас будет два указателя, первый указывает на начало массива столбцов фиксированной строки матрицы А, второй - транспонированной матрицы В. В цикле идем первым указателем по массиву, второй указатель будем сдвигать вправо пока значение меньше, чем значение первого указателя. Если значение первого и второго указанных элементов совпали, то добавляем произведение в ответ. Данное решение будет работать за $\mathcal{O}(n)$.
\par При реализации параллельной функции опытным путём было замечено, что данная реализация является хотспотом и нуждается в доработке.
\par Для компенсации времени работы программы было принято решение использовать дополнительную память. Таким образом, мы компенсируем время работы программы, используя память. Введем новый массив, который будет хранить в себе информацию о посещенных нами столбцах при проходе по массиву столбцов матрицы А. При проходе по массиву столбцов транспонированной матрицы В достаточно лишь посмотреть на значение в вспомогательном массиве. Данное решение также будет работать за $\mathcal{O}(n)$, затраты по памяти будут $\mathcal{O}(n)$. Экспериментально доказано, что данное решение работает быстрее, чем предыдущее.
\par Внутри реализованной секции будет присутствовать условие на проверку равенства элемента вспомогательного массива -1. При запуске Intel® VTune™ Profiler данное условие будет являться хотспотом. Устранить данную проблему можно, используя дополнительный элемент в вспомогательном массиве, который будет равен 0. Тогда изначально вспомогательный массив будет заполнен не -1, а индексом в массиве, где содержится 0. Тогда в случае несовпадения столбцов будет производиться умножение на 0, то есть результат не изменится. Данное предположение позволило получить небольшой прирост в производительности и избавиться от хотспотов в реализации.
\newpage
% Схема распараллеливания
\section*{Схема распараллеливания}
\addcontentsline{toc}{section}{Схема распараллеливания}
Рассмотрим параллельную реализацию алгоритма умножения разреженных матриц.

\par Идея распараллеливания алгоритма достаточно очевидна. Во внешнем цикле перебираем строки матрицы А и далее работаем с ними независимо.
\par Внутренний цикл бесполезно распараллеливать, потому что это повлечет за собой дополнительные накладные расходы и ускорение будет гораздо меньше ожидаемого.
\par При распараллеливании внешнего цикла критической секцией будет являться запись в конец массивов индексов и столбцов. Для реализации доступа к критической секции придется использоваться мьютексы, это может сильно повлиять на время выполнения программы.
\par Оптимизация будет заключаться в создании вспомогательных массивов для каждой строки результирующего массива. Таким образом, запись уже не будет являться критической секцией, так как к каждой строке доступ имеет только один поток.
После выполнения параллельной секции, необходимо слить данные из созданных массивов в один.
Вновь, с помощью использования дополнительной памяти мы компенсировали время работы программы.

\newpage

% Описание программной реализации
\section*{Описание программной реализации}
\addcontentsline{toc}{section}{Описание программной реализации}
Разреженная матрица хранится в виде следующего класса:

\begin{lstlisting}
class SparseMatrix {
 public:
    explicit SparseMatrix(int _size = 0);
    SparseMatrix(const SparseMatrix & a);
    SparseMatrix(const std::vector<std::complex<double>> & a, int _size);
    ~SparseMatrix() = default;
    SparseMatrix& operator=(const SparseMatrix & a);
    SparseMatrix operator*(const SparseMatrix & a);
    std::vector<std::complex<double>> getValues() const;
    std::vector<int> getCols() const;
    std::vector<int> getPointers() const;
    int getSize() const;
    void setSize(const int size);
    void setValues(const std::vector<std::complex<double>> & val);
    void setCols(const std::vector<int> & col);
    void setPointers(const std::vector<int> & pointers);
    std::vector<std::complex<double>> getDenseMatrix() const;
    SparseMatrix transposition() const;
    SparseMatrix openMPMultiplication(const SparseMatrix & a);
    SparseMatrix TBBMultiplication(const SparseMatrix & a, const int threads);
    SparseMatrix threadMultiplication(const SparseMatrix & a);
 private:
    int size;
    std::vector<std::complex<double>> values;
    std::vector<int> cols, pointers;
};
\end{lstlisting}
\par Реализация параллельного алгоритма умножения разреженных матриц представлена в функциях:
\begin{lstlisting}
SparseMatrix openMPMultiplication(const SparseMatrix & a);
SparseMatrix TBBMultiplication(const SparseMatrix & a, const int threads);
SparseMatrix threadMultiplication(const SparseMatrix & a);
\end{lstlisting}
\par В качестве входных параметров передаются матрицы, которые нужно перемножить, а выходным является результирующая матрица.
\newpage

% Подтверждение корректности
\section*{Подтверждение корректности}
\addcontentsline{toc}{section}{Подтверждение корректности}
Для проверки эффективности и корректности работы программы используются тесты, написанные с помощью Google Testing Framework.
\par Они проверяют эффективность работы параллельной схемы (путем сравнения времени выполнения параллельной и последовательной реализации) и корректность вычислений (проверкой правильности формирования массивов разреженной матрицы и проверкой точности - операцией скалярного умножения векторов).

\par Успешное прохождение всех тестов подтверждает корректность работы написанной программы.

\newpage

% Результаты экспериментов
\section*{Результаты экспериментов}
\addcontentsline{toc}{section}{Результаты экспериментов}
Вычислительные эксперименты для оценки эффективности параллельного алгоритма умножения разреженных матриц проводились на оборудовании со следующей аппаратной конфигурацией:

\begin{itemize}
\item Процессор: Intel Core i5-7500, 3.7 GHz, 4 ядра, HT: Off
\item Оперативная память: 24 Гб
\item ОС: Майкрософт Windows 10
\end{itemize}

\begin{tikzpicture}
\begin{axis}[
    title = Результаты экспериментов при размере матрицы $4000$ * $4000$,
	xlabel = {Количество ненулевых элементов $(10^3)$},
	ylabel = {Время, сек},
	width = 400, 
	height = 400,
	legend pos = north west, 
    ymin = 0.6, 
    xmin = 0,
    grid = major,
]
\legend{ 
	Последовательная реализация,
	openMP реализация,
	TBB реализация,
	std::thread реализация,
};
\addplot coordinates {
	(4, 2.538)
	(8, 2.659)
	(12, 2.653)
	(16, 2.753)
	(20, 2.760)
	(24, 2.763)
	(28, 2.715)
	(32, 2.759)
	(36, 2.745)
	(40, 2.831)
	(80, 3.113)
	(120, 3.534)
	(160, 4.016)
	(200, 4.314)
	(240, 4.808)
	(280, 5.338)
	(320, 6.123)
	(360, 6.603)
	(400, 7.285)
};
\addplot coordinates {
	(4, 0.685)
	(8, 0.695)
	(12, 0.722)
	(16, 0.759)
	(20, 0.734)
	(24, 0.772)
	(28, 0.76)
	(32, 0.768)
	(36, 0.764)
	(40, 0.822)
	(80, 0.898)
	(120, 1.066)
	(160, 1.2)
	(200, 1.4)
	(240, 1.538)
	(280, 1.596)
	(320, 1.73)
	(360, 1.817)
	(400, 2.10)
};
\addplot coordinates {
	(4, 0.693)
	(8, 0.69)
	(12, 0.707)
	(16, 0.741)
	(20, 0.754)
	(24, 0.763)
	(28, 0.744)
	(32, 0.754)
	(36, 0.774)
	(40, 0.799)
	(80, 0.901)
	(120, 1.078)
	(160, 1.195)
	(200, 1.375)
	(240, 1.466)
	(280, 1.6)
	(320, 1.757)
	(360, 1.853)
	(400, 2.086)
};
\addplot coordinates {
	(4, 0.697)
	(8, 0.707)
	(12, 0.716)
	(16, 0.713)
	(20, 0.725)
	(24, 0.818)
	(28, 0.770)
	(32, 0.845)
	(36, 0.806)
	(40, 0.790)
	(80, 1.010)
	(120, 1.076)
	(160, 1.208)
	(200, 1.449)
	(240, 1.631)
	(280, 1.651)
	(320, 1.779)
	(360, 1.973)
	(400, 2.365)
};
\end{axis}
\end{tikzpicture}

\par По данным экспериментов можно сделать вывод, что параллельный алгоритм работает намного быстрее, чем последовательный. Максимальное ускорение - 3.5 раза, теоретически максимальное ускорение - 4 раза. Как можно видеть по результатам экспериментов, среди трех использованных стандартов распараллеливания нет единственно быстрого, при разных размерностях поведение различно.
\newpage

% Заключение
\section*{Заключение}
\addcontentsline{toc}{section}{Заключение}
В ходе выполнения лабораторной работы был реализован последовательный и параллельный вариант алгоритма умножения разреженных матриц, хранящихся в формате CRS. Было применено некоторое количество как алгоритмических, так и аппаратных оптимизаций, которые помогли достигнуть поставленных перформанс целей. При тестировании программы в ННГУ на компьюетере с 12 потоками производительности составляла 10.5 раз, что по моему скромному мнению является хорошим результатом.

\newpage

% Список литературы
\begin{thebibliography}{1}
\addcontentsline{toc}{section}{Список литературы}
\bibitem{Sysoev} Сысоев А.В., Мееров И.Б., Свистунов А.Н., Курылев А.Л., Сенин А.В., Шишков А.В., Корняков К.В., Сиднев А.А. «Параллельное программирование в системах с общей памятью. Инструментальная поддержка». Учебно-методические материалы по программе повышения квалификации «Технологии высокопроизводительных вычислений для обеспечения учебного процесса и научных исследований». Нижний Новгород, 2007, 110 с. 
\bibitem{Gergel}
Гергель В. П. Теория и практика параллельных вычислений. – 2007. 
\bibitem{Gergel}
Гергель В. П., Стронгин Р. Г. Основы параллельных вычислений для многопроцессорных вычислительных систем. – 2003.
\bibitem{cppreference} cppreference [Электронный ресурс] // https://en.cppreference.com/w/
\end{thebibliography}
\end{document}
